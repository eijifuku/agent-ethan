meta:
  schema_version: 1
  name: langchain_rag
  defaults:
    llm: openai:gpt-4o-mini

state:
  shape:
    query: str
    answer: str | null
    sources: list[dict]
    preliminary_answer: str | null
  reducer: deepmerge
  init:
    answer: null
    sources: []
    preliminary_answer: null

prompts:
  partials:
    instructions: |
      Answer concisely using the provided context. If unsure, say you do not know.
  templates:
    compose:
      system: "{{> instructions }}"
      assistant: |
        Draft answer from retriever: {{ preliminary_answer }}
      user: |
        Question: {{ query }}
        Context:
        {%- for item in sources %}
        - {{ item.snippet }} ({{ item.source }})
        {%- endfor %}

memory:
  enabled: false

tools:
  - id: knowledge_base
    kind: langchain
    mode: class
    impl: "../tools/langchain_rag.py#ChromaRetrievalQATool"
    config:
      init:
        corpus_path: "./examples/corpus"
        glob: "*.md"
        collection_name: "agent-ethan-docs"
        persist_directory: "./examples/chroma_store"
        embedding_model: "text-embedding-3-small"
        llm_model: "gpt-4o-mini"
        top_k: 4
        recreate_store: true

graph:
  inputs: [query]
  outputs: [answer, sources]
  nodes:
    - id: retrieve
      type: tool
      uses: knowledge_base
      inputs:
        query: "{{ query }}"
      map:
        set:
          sources: "{{ result['items'] }}"
          preliminary_answer: "{{ result['json']['answer'] }}"

    - id: summarise
      type: llm
      prompt: compose
      map:
        set:
          answer: "{{ output.text }}"

  edges:
    - from: retrieve
      to: summarise
